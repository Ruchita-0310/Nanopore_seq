# 1. Quality control
Before doing any quality control, concatenate all the passed reads into one file 
```
cat ./fastq_pass/*.fastq.gz > passed_reads.fastq.gz
```
```
squeue -u ruchita.solanki
watch squeue -u ruchita.solanki #command to see what is running
```
## 1.1 Porechop
[Porechop](https://github.com/rrwick/Porechop) eventhough it is no longer available, you could still use
it. 
Guppy basecaller does the adapter trimming. Still better to use porechop. 
```
conda create -n porechop #created new env
conda activate porechop
conda install -c bioconda porechop
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=15G
#SBATCH --partition=bigmem
####### Run your script #########################
porechop -i passed_reads.fastq.gz -o passed_reads_trimmed.fastq.gz -t 12
sbatch porechop
```
## 1.2 Filtlong
[Filtlong](https://github.com/rrwick/Filtlong) a tool for filtering long reads. 
You could use job scheduler like SLURM. 
```
conda create --name filtlong -c bioconda filtlong #made new env called filtlong
conda activate filtlong
filtlong --min_mean_q 80 passed_reads_trimmed.fastq.gz| gzip > final_reads.fastq.gz
#will produce final_reads.fastq.gz file which will be used for downstream analysis
```
[Mean q](https://github.com/rrwick/Filtlong#read-scoring) is set to 80 to remove the reads that were less than 80% correct which was already done by guppy. So you can play around with different mean_q values to get a better assembly. 
I used 80% and 95% and will compared it using flye. 
95% is too high to get circular genomes. So keep mean q to 80%. 
## 1.3 Nanoplot
[NanoPlot](https://github.com/wdecoster/NanoPlot) is a good tool to visualize the data
```
module load python/3.10.4
pip3 install NanoPlot
nano nanoplot #creating a job script
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=1G
#SBATCH --partition=cpu2019
####### Run your script #########################
NanoPlot -t 8 --fastq final_reads.fastq.gz --maxlength 4000000 --plots dot --legacy hex
sbatch nanoplot_test.sbatch #command to run job script
```
# 2. Assembly
## 2.1 Flye - works well for metagenomics 
[Flye](https://github.com/fenderglass/Flye) is an assembler. Especially good for metagenomic analysis.
```
conda install -c bioconda flye #in filtlong env
conda activate filtlong
nano flye #creating a job script
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=15G
#SBATCH --partition=bigmem
####### Run your script #########################
flye --nano-raw final_reads.fastq.gz --meta --genome-size 15m --out-dir assembly_flye -i 0 --threads 8
sbatch flye
```
[Seqtk](https://github.com/lh3/seqtk) is a tool kit that helps you create a subset of sequences to run checkm2/gtdb-tk on.
While trycycler is running, you could download [Bandage](https://github.com/rrwick/Bandage) to visualize the contigs produced by Flye. Some contigs will be circular and you could run checkm and gtdb-tk. 
```
conda install -c bioconda seqtk
nano seqtk_names
seqtk subseq assembly.fasta seqtk_names > out.fq
```
# 3. Polishing
## 3.1 Minimap2 
[Minimap2](https://github.com/lh3/minimap2) is a versatile sequence alignment program that aligns DNA or mRNA sequences against a large
reference database. 
- It also finds overlaps between long reads with error rate up to ~15%.
- Used along side with Racon 3 times
```
conda create -n minisuite
conda activate minisuite
conda install -c bioconda minimap2
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=100G
#SBATCH --partition=bigmem
conda activate minisuite
###mapping -1
minimap2 -ax map-ont -t 14 assembly.fasta final_reads.fastq.gz > /work/ebg_lab/eb/Ruchita_working/nano_data/passed_qc/assembly_flye_1/minimap2.sam
###mapping -2
minimap2 -ax map-ont -t 14 racon1.fasta final_reads.fastq.gz > /work/ebg_lab/eb/Ruchita_working/nano_data/passed_qc/assembly_flye_1/2minimap2.sam
###mapping -3
minimap2 -ax map-ont -t 14 racon2.fasta final_reads.fastq.gz > /work/ebg_lab/eb/Ruchita_working/nano_data/passed_qc/assembly_flye_1/3minimap2.sam
###mapping -4
minimap2 -ax map-ont -t 14 racon3.fasta final_reads.fastq.gz > /work/ebg_lab/eb/Ruchita_working/nano_data/passed_qc/assembly_flye_1/4minimap2.sam

###create indexing
minimap2 -d catalogue.mmi final_reads.fastq.gz
minimap2 -L -ax map-ont catalogue.mmi final_reads.fastq.gz > aln.sam
```
- Convert aln.sam file to bam file, sort it and write-index 
- The created indexed bam files will be used in CONCOCT!

## 3.2 Racon
[Racon](https://github.com/isovic/racon) is a standalone consensus module to correct raw contigs generated by rapid assembly methods which
do not include a consensus step. 
```
conda create -n racon
conda activate racon
conda install -c bioconda racon
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=100G
#SBATCH --partition=bigmem
conda activate racon
###polishing -1 
racon -t 14 assembly.fasta minimap2.sam final_reads.fastq.gz > racon1.fasta
###polishing -2
racon -t 14 assembly.fasta 2minimap2.sam racon1.fasta > racon2.fasta
###polishing -3
racon -t 14 assembly.fasta 3minimap2.sam racon2.fasta > racon3.fasta
```
## 3.3 Medaka 
[Medaka](https://github.com/nanoporetech/medaka) a tool to create consensus sequences
Use it 2 times
```
conda create -n py37env python=3.7
conda activate py37env
python --version #Python 3.7.16
pip install medaka
pip install numpy==1.21.6
pip install tensorflow==2.10.0    
conda install -c bioconda bcftools=1.15.1
conda install -c bioconda bgzip     
conda install -c bioconda minimap2 
conda install -c bioconda samtools  
conda install -c bioconda tabix=1.11  
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=15G
#SBATCH --partition=bigmem
####### Run your script #########################
conda activate py37env
medaka_consensus -i final_reads.fastq.gz -d racon3.fasta -o medaka_out #-i input_reads.fasta, -d reference.fasta, -o output_directory
sbatch medaka
```
# 4. Bining 
## 4.1 MetaBAT2
[MetaBAT2](https://bitbucket.org/berkeleylab/metabat/src/master/) is statistical framework for reconstructing genomes from metagenomic data. 
```
wget https://bitbucket.org/berkeleylab/metabat/get/master.tar.gz
tar xzvf master.tar.gz
cd berkeleylab-metabat-*
mkdir build && cd build && cmake /your/path/build && make && make test && make install
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=15G
#SBATCH --partition=bigmem
####### Run your script #########################
conda activate metawrap-env
metabat2 -i racon3.fasta -o wrap/metabat_out -s 500000
```
- Produced 38 .fa files/bins 
## 4.2 MaxBin2
[MaxBin2](https://sourceforge.net/projects/maxbin2/) is a software for binning assembled metagenomic sequences
- copy it on arc in software directory
```
tar -xvf MaxBin-2.2.7
cd MaxBin-2.2.7
cd src
make
cd .. #go back to MaxBin-2.2.7 directory
./autobuild_auxiliary
run_MaxBin.pl -h
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=15G
#SBATCH --partition=bigmem
####### Run your script #########################
conda activate metawrap-env
run_MaxBin.pl -contig racon3.fasta -out wrap/maxbin_out 
```
- Produced 15 .fasta files/bins and 1 .tar.gz file
## 4.3 CONCOCT
[CONCOCT](https://concoct.readthedocs.io/en/latest/usage.html) does unsupervised binning of metagenomic contigs by using nucleotide composition - kmer frequencies - and coverage data for multiple samples. CONCOCT can accurately (up to species level) bin metagenomic contigs.
```
conda create -n concoct
conda activate concoct
conda install -c bioconda concoct
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=15G
#SBATCH --partition=bigmem
####### Run your script #########################
###cut contigs into smaller parts
cut_up_fasta.py racon3.fasta -c 10000 -o 0 --merge_last -b contigs_10K.bed > contigs_10K.fa
###Generate table with coverage depth information per sample and subcontig
concoct_coverage_table.py contigs_10K.bed sorted.bam > coverage_table.tsv
###Run concoct
concoct --composition_file contigs_10K.fa --coverage_file coverage_table.tsv -b concoct_output/
###Merge subcontig clustering into original contig clustering
merge_cutup_clustering.py concoct_output/clustering_gt1000.csv > concoct_output/clustering_merged.csv
###Extract bins as individual FASTA
mkdir concoct_output/fasta_bins
extract_fasta_bins.py racon3.fasta concoct_output/clustering_merged.csv --output_path concoct_output/fasta_bins
```
## 4.4 MetaWRAP
[MetaWRAP](https://github.com/bxlab/metaWRAP) 
- You will install metaBAT2 and maxbin2 when you install metawrap. If you want you can skip the above mentioned installation method. 
```
mamba create -y -n metawrap-env python=2.7
mamba activate metawrap-env
git clone https://github.com/bxlab/metaWRAP.git
mkdir MY_CHECKM_FOLDER
cd MY_CHECKM_FOLDER
wget https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz
tar -xvf *.tar.gz
rm *.gz
cd ../
mamba install biopython blas=2.5 blast=2.6.0 bmtagger bowtie2 bwa checkm-genome fastqc krona=2.7 matplotlib maxbin2 megahit metabat2 pandas prokka quast r-ggplot2 r-recommended salmon samtools=1.9 seaborn spades trim-galore concoct=1.0 pplacer
```
For [bin refinement](https://github.com/bxlab/metaWRAP/blob/master/Usage_tutorial.md) follow step 5
- ```-c 90 -x 5``` the minimum completion is set to 90% and maximum contamination to 5%
- ```-A``` is bins produced by metabat2, ```-B``` is bins produced by maxbin2, and ```-C``` is bins produced by CONCOCT
- Make sure you have nothing other than .fasta or .fa files in your bin directories. 
```
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=100G
#SBATCH --partition=bigmem
####### Run your script #########################
metawrap bin_refinement -o BIN_REFINEMENT -t 96 -A metabat2_bins/ -B maxbin2_bins/ -C fasta_bins/ -c 90 -x 5 
```
For [reassembly](https://github.com/bxlab/metaWRAP/blob/master/Usage_tutorial.md) follow step 8
```
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=100G
#SBATCH --partition=bigmem
####### Run your script #########################
metawrap reassemble_bins -o BIN_REASSEMBLY -b metawrap_50_10_bins/ -1 final_reads_1.fastq -2 final_reads_2.fastq --nanopore final_reads.fastq.gz
```

# 5. Assembly processing 
## 5.1 CheckM
## 5.2 GTDB-Tk
# GTDB-TK
```
conda create -n gtdbtk-2.3.2 -c conda-forge -c bioconda gtdbtk=2.3.2
download-db.sh
conda activate gtdbtk-2.3.2
#!/bin/bash
####### Reserve computing resources #############
#SBATCH --nodes=1
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=4
#SBATCH --time=24:00:00
#SBATCH --mem=100G
#SBATCH --partition=bigmem
gtdbtk classify_wf --genome_dir /work/ebg_lab/eb/Ruchita_working/nano_data/passed_qc/assembly_flye_1/wrap/BIN_REFINEMENT/metawrap_50_10_bins --out_dir /work/ebg_lab/eb/Ruchita_working/nano_data/passed_qc/assembly_flye_1/wrap/BIN_REFINEMENT/metawrap_50_10_bins/classify_out --skip_ani_screen --extension fa
```
## 5.3 Prodigal
